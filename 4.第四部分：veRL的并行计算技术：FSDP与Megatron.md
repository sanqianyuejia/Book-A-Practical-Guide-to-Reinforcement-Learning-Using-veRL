# 第四部分：veRL 的并行计算技术：FSDP 和 Megatron
## 1. 分布式训练中的数据并行与模型并行
在训练大型深度学习模型时，尤其是对于大型语言模型的强化学习任务，由于其巨大的计算量和内存需求，单台机器往往无法满足要求，因此需要采用并行计算技术。分布式训练是解决这一问题的关键方法，它通过将计算任务分摊到多个计算设备（通常是 GPU）上，从而加速训练过程并支持更大规模的模型。在分布式训练中，两种主要的并行策略是数据并行（Data Parallelism）和模型并行（Model Parallelism）。

~~~
1. 这里说的分布式训练，与 并行计算，是否存在某种关联？？？
2. 能否将这种关联解释清楚，以便让读者恍然大悟？？？
3. 我到现在也还没搞清楚，分布式训练 与 并行计算 的必然联系是什么？？？
~~~

数据并行是指将训练数据集分割成多个小的批次（Mini-batches），然后将这些批次分配给不同的计算设备。每个设备都拥有模型的完整副本，并在分配给自己的数据批次上独立地进行前向传播、计算损失和反向传播计算梯度。在每个训练步骤结束时，所有设备上的梯度需要进行同步（例如，通过平均），然后每个设备上的模型副本使用同步后的梯度进行参数更新。<span style="color: red;">这里能否用一个图，或者动态图，将每个批次上的计算、以及计算结果如何同步、合并说明清楚</span> 数据并行能够有效地利用计算设备的能力，加速训练过程。

~~~
1. 数据并行，典型的特点是什么？
2. 使用数据并行模式后，计算发生了什么变化？
3. 什么情况下使用数据并行？？？举一些实际的示例
~~~

模型并行是指将模型本身分割成多个部分，然后将这些部分分配给不同的计算设备。当模型太大，无法在单个计算设备的内存中容纳时，模型并行就变得至关重要。根据模型分割的方式，模型并行可以进一步分为张量并行（Tensor Parallelism）和流水线并行（Pipeline Parallelism）等。<span style="color: red;">除此之外，还有别的吗？</span> 张量并行是将模型中的单个张量（例如，神经网络曾中的权重矩阵）分割到多个设备上进行计算。流水线并行是将模型的不同层或模块分配到不同的设备上，形成一个计算流水线，使得不同的设备可以同时处理输入数据的不同阶段。

~~~
1. 模型并行，典型特点是什么？是否还分张量并行和流水线并行？？？
2. 流水线并行为啥可以同时处理输入数据的不同阶段？？？
~~~

veRL 平台通过集成 Fully Sharded Data Parallelism (FSDP) 和 Megatron-LM 框架，同时支持数据并行和模型并行这两种主要的并行计算技术，为训练大规模强化学习模型提供了强大的能力。

~~~
1. 这些并行方法，与上一部分的的 Ray 分布式计算方法，有什么差异和关联？
2. 每一种并行方法的实现细节，是什么样的？
3. 数据并行与模型并行的本质区别是什么？
4. FSDP 与 Megatron-LM 在技术路线上的本质区别是什么？
5. 补充 数据并行 与 模型并行 的横向对比图？对比包括哪些维度？
6. 补充 FSDP 与 Megatron-LM 的横向对比图？对比包括哪些维度？
7. 补充 FSDP 在 参数、梯度和优化器状态方面的纵向对比图？FSDP 对这些数据的切分差异和逻辑分别是什么？
8. 切分的概念怎么理解？对行/列的切分差异？关键操作：all-gather、reduce-scatter，all-reduce 等概念的解释？
~~~

总而言之，分布式训练通过数据并行（分割数据）和模型并行（分割模型）来克服训练大模型的计算和内存限制。veRL 通过集成 FSDP 和 Megatron 同时支持这两并行策略。

## 2. FSDP 原理与在 veRL 中的应用
Fully Sharded Data Parallelism（FSDP）是一种先进的数据并行技术，旨在提高训练大规模深度学习模型时的内存效率和可扩展性。传统的 data parallelism 中，每个 GPU 都需要存储模型的完整副本，这限制了可以训练的模型大小。FSDP 的核心思想是将模型的整个状态（包括参数、梯度和优化器状态）在所有可用的 GPU 之间进行分片（Sharding），而不是在每个 GPU 上复制完整的模型。这意味着每个 GPU 只需要存储模型状态的一部分，从而显著降低了每个 GPU 的内存占用，使得可以训练更大规模的模型。

~~~
备注：FSDP 将传统的数据并行，做了优化，通过对状态进行分片，进一步降低对单个 GPU 显存的要求。所以，本质上可以说是一种优化过的数据并行技术。
~~~

在训练过程中，当某个 GPU 需要进行特定的计算时，它会临时性地从其他 GPU 获取所需的模型参数片段。计算完成后，梯度会被计算出来，并同样进行分片存储。在参数更新阶段，优化器的状态也会被分片存储和更新。FSDP 通过这种方式，实现了在保持数据并行的训练效率的同时，极大地提高了内存的利用率。

~~~
此处需要：一个详细的实现原理图
~~~

在 veRL 平台中，FSDP 被作为一个重要的训练后端进行集成。使用 FSDP 的主要优势在于能够训练更大规模的模型，提高内存效率，并且相较于传统的 data parallelism，可能在某些情况下实现更快的训练速度，尤其是在内存成为瓶颈时。

在 veRL 中配置和使用 FSDP 通常需要在训练配置文件中指定 FSDP 作为训练后端，并可能需要调整一些 FSDP 特有的参数，例如分片策略等。veRL 的 API 也会提供相应的接口来初始化和管理 FSDP 的训练过程。

~~~
这里需要：veRL 的训练配置文件示例
~~~

总而言之，FSDP 是一种内存高效的数据并行技术，veRL 利用 FSDP 使得用户能够训练更大规模的强化学习模型，其原理在于将模型状态在多个设备之间进行分片储存。用户需要在 veRL 中进行相应的配置才能启用和使用 FSDP。

~~~
1. 技术论文：PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel，阐述了 PyTorch 中 FSDP 的设计原理、实现细节和优化技术等，还对 FSDP 在扩展大型语言和推荐模型方面的性能表现进行了评估，表明其具有近似线性的可扩展性：https://www.vldb.org/pvldb/vol16/p3848-huang.pdf
2. 技术论文：Fully Sharded Data Parallel: Training Large Models with Limited Memory，介绍了 FSDP 的背景知识、研究方法和实验结果，通过与全参数训练和其他并行策略的对比，展示了 FSDP 在内存优化、可扩展性、通信开销和内存占用等方面的显著优势。https://arxiv.org/pdf/2407.17243.pdf
3. 技术论文：How to Train Long-Context Language Models(Effectively)，在实现细节部分，以实际案例介绍了在使用 FSDP 进行长文本上下文语言模型训练时，如何与其他技术相结合，以及如何通过智能批处理算法等优化 FSDP 的训练速度等，https://arxiv.org/pdf/2410.02660
4. 官方文档：PyTorch Fully Sharded Data Parallel (FSDP)，作为 PyTorch 官方文档，提供了 FSDP 的详细说明，包括其基本概念、使用方法、相关 API 文档以及常见问题解决等，是学习 FSDP 实现细节的权威资料。https://pytorch.org/docs/stable/fsdp.html
5. 博客与教程：An Introduction to FSDP (Fully Sharded Data Parallel) for Distributed Training：以通俗易懂的方式介绍了 FSDP 的工作原理、关键特性和实现方式，还通过与其他数据并行方法的对比，突出了 FSDP 的优势，并提供了实际的代码示例帮助读者更好地理解和应用 FSDP。https://medium.com/@siddharthashrestha/an-introduction-to-fsdp-fully-sharded-data-parallel-for-distributed-training-5e67adfa1712
6. 博客与教程：PyTorch Fully Sharded Data Parallel (FSDP) on AMD GPUs with ROCm：主要介绍了如何在 AMD GPU 上使用 FSDP 进行训练，包括 FSDP 的工作流程、实现细节以及如何在多 GPU 和多节点环境下进行微调等内容，并给出了相关的实验结果分析，可帮助读者了解 FSDP 在不同硬件平台上的实现和优化方法，https://rocm.blogs.amd.com/artificial-intelligence/fsdp-training-pytorch/README.html
7. 博客与教程：Fully Sharded Data Parallel (FSDP) | Karthick Panner Selvam：详细介绍了 FSDP 的实现方式，包括如何使用 PyTorch API 搭建 FSDP 模型、关键配置选项如 CPU 卸载和分片策略等的实际应用，还提供了使用 FSDP 进行模型微调的具体代码示例，https://karthick.ai/blog/2024/Fully-Sharded-Data-Parallel-(FSDP)/
~~~
## 3. Megatron 原理与在 veRL 中的应用
Megatron 是 NVIDIA 开发的一个用于训练超大型 Transformer 模型（如，LLM）的框架，其核心原理是模型并行，特别是张量并行（Tensor Parallelism）和流水线并行（Pipeline Parallelism）。当模型参数量巨大，即使使用 FSDP 也无法在单个或一组机器的内存中容纳时，就需要采用 Megatron 的模型并行策略。

~~~
张量并行：
1. 原理 ：将张量切分并在多个 GPU 上并行计算。例如，在 Transformer 模型的自注意力机制中，查询（Query）、键（Key）、值（Value）矩阵会被切分，每个 GPU 只负责计算属于自己的部分。
2. 切分方式 ：常见的有列切分、行切分和混合切分。列切分常用于全连接层的权重矩阵，将矩阵按列分到不同 GPU 上；行切分则是将矩阵按行分到不同 GPU 上。
流水线并行：
1. 原理 ：将模型的不同层或模块分配到不同的 GPU 上，形成流水线。每个 GPU 负责处理一部分计算任务，数据在 GPU 之间流动，通过流水线的方式提高计算效率。
2. 调度策略 ：一般需要设计合理的流水线调度策略，以确保流水线的高效运行。如简单的轮转调度，每个 mini-batch 依次通过流水线中的各个 stage。
数据并行：
1. 原理 ：在张量并行和流水线并行的基础上，再结合数据并行，将多个副本的模型分布在不同的 GPU 上，每个副本处理不同的数据子集，并在反向传播时同步梯度。
2. 通信策略：梯度同步通常采用全归约操作，将各个 GPU 计算的梯度汇总并广播回各个 GPU。
~~~

~~~
参考文献：
1. 学术论文：Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism，该论文详细介绍了 Megatron-LM 的设计和实现原理，包括其模型并行架构、并行模式组合策略、通信优化技术等，还展示了 Megatron-LM 在大规模语言模型训练中的应用和性能表现，为 Megatron 技术体系的理论基础和核心实现方法提供了权威的学术参考，https://arxiv.org/abs/1909.08053?file=1909.08053

2. 技术博客：Megatron-LM 深度解析：原理、应用与代码实现，https://blog.csdn.net/l35633/article/details/146168805

3. 官方文档和代码仓库：https://github.com/NVIDIA/Megatron-LM
~~~

张量并行是指将神经网络中的单个张量（例如，Transformer 层中的权重矩阵）分割到多个 GPU 上进行计算。<span style="color: red;">这种表述不太对，相对于 FSDP 的切分方式，Megatron 的切分，颗粒度更大？？？</span> 例如，一个大模型的矩阵乘法操作可以被分解成多个小的矩阵乘法操作，分别在不同的 GPU 上执行，然后将结果进行聚合。

~~~
数据并行参考资料：
1. 技术博客：深度学习中的并行策略：数据并行、流水并行与张量并行，介绍了数据并行的基本原理、优点、缺点以及适用场景等，https://blog.csdn.net/2302_80236633/article/details/146296786

2. 学术论文：Distributed Training of Deep Learning Models: A Taxonomic Perspective，文中详细阐述了数据并行的原理，包括基本步骤、适用性、数据流周期以及集群映射方式等内容，https://arxiv.org/pdf/2007.03970

3. 技术博客：LLM分布式训练2---并行策略之数据并行，以PyTorch为例，介绍了数据并行的实现方法，包括nn.DataParallel和nn.DistributedDataParallel的使用，以及如何通过DistributedSampler和DistributedDataParallel进行分布式训练等内容，https://miracle-techlink.github.io/posts/3a50363.html
~~~

~~~
张量并行参考资料：
1. 学术论文：Breadth-First Pipeline Parallelism，文中定义了张量并行的概念，介绍了其工作原理、限制以及与其他方法结合的情况。https://arxiv.org/pdf/2211.05953v1

2. CSDN博客：一文详解张量并行Tensor parallel的概念和原理应用，从概念、区别与联系三个方面展开了对张量并行的分析。https://blog.csdn.net/my_name_is_learn/article/details/146472261

3. 学术论文：Accelerating Heterogeneous Tensor Parallelism via Flexible Workload Control，文中介绍了模型并行的背景和分类，重点阐述了Transformer中的张量并行两种模式以及通信和计算密集型行为。https://arxiv.org/pdf/2401.11469

4. arXiv.org：A Novel Tensor-Expert Hybrid Parallelism Approach to Scale Mixture-of-Experts Training，描述了一种结合了专家并行、MegatronLM的张量并行和数据并行的方法，用于训练具有大型基础模型的MoE模型。https://arxiv.org/pdf/2303.06318v1

5. arXiv.org：OSDP: Optimal Sharded Data Parallel for Distributed Deep Learning，文中在介绍其他并行训练策略时，阐述了张量并行如何将模型张量划分为多个部分并在不同设备上分别进行训练以降低内存成本。https://arxiv.org/pdf/2209.13258v4

6. arXiv.org：xDiT: an Inference Engine for Diffusion Transformers(DiTs) with Massive Parallelism，文中介绍了张量并行在扩散模型中的应用和其在推理时的通信开销问题。https://arxiv.org/pdf/2411.01738
~~~

流水线并行是指将模型的不同层或模块分配到不同的 GPU 上，形成一个计算流水线。当一个批次的数据通过流水线时，不同的 GPU 可以同时处理该批次数据的不同部分（例如，第一个 GPU 处理前几层，第二个 GPU 处理中间几层，以此类推）。

在 veRL 平台中，Megatron-LM 被集成作为一个可选的训练后端。使用 Megatron 的主要优势在于能够训练参数量非常大的模型，这些模型可能无法通过数据并行（包括 FSDP）单独进行训练。

在 veRL 中配置和使用 Megatron 通常需要在训练配置文件中指定 Megatron 作为训练后端，并设置相关的参数，例如张量并行的维度和流水线并行的阶段数。veRL 也会提供相应的 API 来启动和管理基于 Megatron 的训练过程。值得注意的是，veRL 已经兼容 Megatron-LM v0.11.0，并且不再需要对 Megatron-LM 进行额外的补丁。

~~~
参考资料：
1. 技术博客：流水线并行调度详解，https://zhuanlan.zhihu.com/p/20976605756

2. 学术论文：Megatron-LM: Training multi-billion parameter language models using model parallelism，该论文是 Megatron-LM 的核心论文，详细介绍了 Megatron-LM 的设计和实现原理，包括其模型并行架构、并行模式组合策略、通信优化技术等，还展示了 Megatron-LM 在大规模语言模型训练中的应用和性能表现。https://arxiv.org/abs/1909.08053?file=1909.08053

3. 学术论文：Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM，这篇论文介绍了 Megatron-LM 的交错式流水线并行方法，以及 3D 并行和参数计算的优化。该方法可以提高训练效率，并减少通信瓶颈。https://arxiv.org/pdf/2104.04473
~~~

总而言之，Megatron 提供的是模型并行的能力，veRL 通过集成 Megatron-LM 使得用户能够训练极其庞大的语言模型，其核心原理包括张量并行和流水线并行。用户需要在 veRL 中进行相应的配置一起用和使用 Megatron 。

## 4. 如何在 veRL 配置和使用 FSDP 与 Megatron

在 veRL 中选择和使用 FSDP 或 Megatron 取决于具体的强化学习训练任务和模型规模。一般来说，如果模型可以在单个或一组机器的内存中通过数据并行进行有效训练，那么 FSDP 通过是一个更好的选择，因为它更容易配置和使用，并且在很多情况下能够提供良好的性能。然而，当模型规模非常庞大，即使使用 FSDP 也无法满足内存需求时，就需要考虑使用 Megatron 的模型并行能力。Megatron 能够支持训练参数量高达数百甚至数千亿的模型。

在 veRL 中配置使用 FSDP 或 Megatron，主要通过修改训练配置文件（例如，YAML 文件）来实现。用户需要在配置文件中指定 training_backend 参数为 fsdp 或 megatron 来选择相应的并行训练后端。此外，还可以根据需要配置与所选后端相关的特定参数。例如，对于 FSDP，可以配置分片策略、混合精度等参数；对于 Megatron，可以配置张量并行的维度（例如，tensor_model_parallel_size）和流水线并行的阶段数（例如，pipline_model_parallel_size）。

以下是一些配置示例：

**使用 FSDP 的配置片段**：
```yaml
trainer:
  type: fsdp
  params:
    mixed_precision: bf16  # 使用 bfloat16 混合精度
    sharding_strategy: FULL_SHARD  # 使用全分片策略
    # 其他 FSDP 相关参数
```

**使用 Megatron 的配置片段**:
```yaml
trainer:
  type: megatron
  params:
    tensor_model_parallel_size: 2  # 张量并行维度为 2
    pipeline_model_parallel_size: 1 # 流水线并行阶段数为 1
    # 其他 Megatron 相关参数
```

在使用 FSDP 或 Megatron 进行训练时，还需要注意一些最佳实践。例如，合理选择批大小（Batch Size）对于提高并行训练效率至关重要。通常情况下，增加批大小可以提高 GPU 的利用率，但也可能影响模型的收敛速度。学习率（Learning Rate）也需要根据所使用的并行策略和批大小进行调整。对于模型并行，可能需要采用更大的学习率或更复杂的学习率调度策略。此外，有效地利用分布式资源，例如通过合理的任务分配和数据加载策略，也是提高并行训练效率的关键。veRL 的文档和社区通常会提供更详细的关于性能调优和最佳实践的指南。

总而言之，在 veRL 中配置和使用 FSDP 或 Megatron 需要根据模型大小和资源约束进行选择，通过修改配置文件指定训练后端和相关参数，并遵循最佳实践以确保高效的并行训练。

### 附录：FSDP 与 Megatron 技术路径的本质区别
| **维度**         | **FSDP**                          | **Megatron-LM**                     |
|------------------|-----------------------------------|--------------------------------------|
| **并行核心**      | 数据并行 + 参数分片               | 模型并行（张量/流水线） + 3D组合     |
| **内存优化**      | 动态分片与释放                    | 模型拆分 + 序列并行                  |
| **通信模式**      | `all-gather`/`reduce-scatter`     | `all-reduce` + 流水线调度            |
| **适用规模**      | 百亿级参数，千卡以下              | 万亿级参数，万卡集群                 |
| **生态定位**      | PyTorch原生支持，灵活易用         | 专用框架，需深度调优                 |

**最终结论**：  
FSDP通过数据并行的分片机制降低显存压力，适合中等规模快速部署；Megatron-LM通过模型并行和3D组合优化极大规模训练的效率，但需复杂配置和硬件支持。两者可结合使用（如FSDP+TP）以平衡内存与通信需求。