# 第四部分：veRL 的并行计算技术：FSDP 和 Megatron
## 1. 分布式训练中的数据并行与模型并行
在训练大型深度学习模型时，尤其是对于大型语言模型的强化学习任务，由于其巨大的计算量和内存需求，单台机器往往无法满足要求，因此需要采用并行计算技术。分布式训练是解决这一问题的关键方法，它通过将计算任务分摊到多个计算设备（通常是 GPU）上，从而加速训练过程并支持更大规模的模型。在分布式训练中，两种主要的并行策略是数据并行（Data Parallelism）和模型并行（Model Parallelism）。

~~~
1. 这里说的分布式训练，与 并行计算，是否存在某种关联？？？
2. 能否将这种关联解释清楚，以便让读者恍然大悟？？？
3. 我到现在也还没搞清楚，分布式训练 与 并行计算 的必然联系是什么？？？
~~~

数据并行是指将训练数据集分割成多个小的批次（Mini-batches），然后将这些批次分配给不同的计算设备。每个设备都拥有模型的完整副本，并在分配给自己的数据批次上独立地进行前向传播、计算损失和反向传播计算梯度。在每个训练步骤结束时，所有设备上的梯度需要进行同步（例如，通过平均），然后每个设备上的模型副本使用同步后的梯度进行参数更新。<span style="color: red;">这里能否用一个图，或者动态图，将每个批次上的计算、以及计算结果如何同步、合并说明清楚</span> 数据并行能够有效地利用计算设备的能力，加速训练过程。

~~~
1. 数据并行，典型的特点是什么？
2. 使用数据并行模式后，计算发生了什么变化？
3. 什么情况下使用数据并行？？？举一些实际的示例
~~~

模型并行是指将模型本身分割成多个部分，然后将这些部分分配给不同的计算设备。当模型太大，无法在单个计算设备的内存中容纳时，模型并行就变得至关重要。根据模型分割的方式，模型并行可以进一步分为张量并行（Tensor Parallelism）和流水线并行（Pipeline Parallelism）等。<span style="color: red;">除此之外，还有别的吗？</span> 张量并行是将模型中的单个张量（例如，神经网络曾中的权重矩阵）分割到多个设备上进行计算。流水线并行是将模型的不同层或模块分配到不同的设备上，形成一个计算流水线，使得不同的设备可以同时处理输入数据的不同阶段。

~~~
1. 模型并行，典型特点是什么？是否还分张量并行和流水线并行？？？
2. 流水线并行为啥可以同时处理输入数据的不同阶段？？？
~~~

veRL 平台通过集成 Fully Sharded Data Parallelism (FSDP) 和 Megatron-LM 框架，同时支持数据并行和模型并行这两种并行策略。

~~~
1. 这些并行方法，与上一部分的的 Ray 分布式计算方法，有什么差异和关联？
2. 每一种并行方法的实现细节，是什么样的？
~~~


## 2. FSDP 原理与在 veRL 中的应用
## 3. Megatron 原理与在 veRL 中的应用
## 4. 如何在 veRL 配置和使用 FSDP 与 Megatron